{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "630a2437",
      "metadata": {
        "id": "630a2437"
      },
      "source": [
        "# Monitoring with Evidently"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c3dfc08",
      "metadata": {
        "id": "3c3dfc08"
      },
      "source": [
        "To install Evidently using the pip package manager, run:\n",
        "\n",
        "```$ pip install evidently```\n",
        "\n",
        "\n",
        "If you want to see reports inside a Jupyter notebook, you need to also install the Jupyter nbextension. After installing evidently, run the two following commands in the terminal from the Evidently directory.\n",
        "\n",
        "To install jupyter nbextension, run:\n",
        "\n",
        "```$ jupyter nbextension install --sys-prefix --symlink --overwrite --py evidently```\n",
        "\n",
        "To enable it, run:\n",
        "\n",
        "```$ jupyter nbextension enable evidently --py --sys-prefix```\n",
        "\n",
        "That's it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aec9a1cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aec9a1cc",
        "outputId": "cd116a91-fb25-460f-9c63-28ed60e14b78"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import evidently\n",
        "except:\n",
        "    !pip install git+https://github.com/evidentlyai/evidently.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0c00061b",
      "metadata": {
        "id": "0c00061b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "from evidently import ColumnMapping\n",
        "\n",
        "from evidently.report import Report\n",
        "from evidently.metrics.base_metric import generate_column_metrics\n",
        "from evidently.metric_preset import DataDriftPreset, TargetDriftPreset, DataQualityPreset, RegressionPreset\n",
        "from evidently.metrics import *\n",
        "\n",
        "from evidently.test_suite import TestSuite\n",
        "from evidently.tests.base_test import generate_column_tests\n",
        "from evidently.test_preset import DataStabilityTestPreset, NoTargetPerformanceTestPreset, RegressionTestPreset\n",
        "from evidently.tests import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "56d3e494",
      "metadata": {
        "id": "56d3e494"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dca5a2c",
      "metadata": {
        "id": "1dca5a2c"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c9d9f9e",
      "metadata": {
        "id": "5c9d9f9e"
      },
      "outputs": [],
      "source": [
        "data = fetch_california_housing(as_frame=True)\n",
        "housing_data = data.frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "60692ed0",
      "metadata": {
        "id": "60692ed0"
      },
      "outputs": [],
      "source": [
        "housing_data.rename(columns={'MedHouseVal': 'target'}, inplace=True)\n",
        "housing_data['prediction'] = housing_data['target'].values + np.random.normal(0, 5, housing_data.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f48b2f20",
      "metadata": {
        "id": "f48b2f20"
      },
      "outputs": [],
      "source": [
        "reference = housing_data.sample(n=5000, replace=False, random_state=123)\n",
        "current = housing_data.sample(n=5000, replace=False, random_state=321)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df8e175e",
      "metadata": {},
      "source": [
        "#### TODO: Print basic statistics of reference and current data\n",
        "- mean\n",
        "- min\n",
        "- max\n",
        "- number of elements\n",
        "- and similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7b55d4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8ba276",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fedb4612",
      "metadata": {
        "id": "fedb4612"
      },
      "source": [
        "## Report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7ab0606",
      "metadata": {},
      "source": [
        "Evidently Reports help explore and debug data and model quality. They calculate various metrics and generate a dashboard with rich visuals.\n",
        "\n",
        "To start, you can use Metric Presets. These are pre-built Reports that group relevant metrics to evaluate a specific aspect of the model performance.\n",
        "\n",
        "Letâ€™s start with the Data Drift. This Preset compares the distributions of the model features and show which have drifted. When you do not have ground truth labels or actuals, evaluating input data drift can help understand if an ML model still operates in a familiar environment.\n",
        "\n",
        "The data drift report compares the distributions of each feature in the two datasets (reference vs current). It automatically picks an appropriate statistical test or metric based on the feature type and volume. It then returns p-values or distances and visually plots the distributions. You can also adjust the drift detection method or thresholds, or pass your own."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0ca332",
      "metadata": {},
      "source": [
        "##### TODO: Create a preset report\n",
        "- Create a Report object with a DataDrift preset included\n",
        "- Use the reference and current datasets created in previous steps\n",
        "- Experiment with changing the statistical test in the report to something else."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb77cbe1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bb77cbe1",
        "outputId": "f604f8a3-4ffe-46f1-80c8-4e494d7b78f7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "16204f72",
      "metadata": {},
      "source": [
        "Evidently Reports are very configurable. You can define which Metrics to include and how to calculate them.\n",
        "\n",
        "To create a custom Report, you need to list individual Metrics. Evidently has dozens of Metrics that evaluate anything from descriptive feature statistics to model quality. You can calculate Metrics on the column level (e.g., mean value of a specific column) or dataset-level (e.g., share of drifted features in the dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3720157",
      "metadata": {},
      "source": [
        "##### TODO: Create a custom report\n",
        "- Display a summary metric for the column `AveRooms`\n",
        "- Display a quantile metric for the 0.25 quantile for the column `Latitude` and `Longitude`\n",
        "- Display the drift metric for the column `HouseAge`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e7de377",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7e7de377",
        "outputId": "fbf29660-d9a0-4fff-842d-da08e883bfef"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0f9cac58",
      "metadata": {},
      "source": [
        "##### TODO: Saving the report\n",
        "- Save the output of the report as html\n",
        "- Get the output of the report as python dict\n",
        "- Get the output of the report as JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "GUmkHWx3uc2j",
      "metadata": {
        "id": "GUmkHWx3uc2j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d72ca314",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d72ca314",
        "outputId": "20b07d51-d294-4ae0-fcb3-8deda6e995cd",
        "scrolled": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab320537",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ab320537",
        "outputId": "ddd17d43-a9f2-4281-c32f-bc62a192511c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1ea31ae7",
      "metadata": {
        "id": "1ea31ae7"
      },
      "source": [
        "## Test Suite"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a87d16",
      "metadata": {},
      "source": [
        "Reports help visually explore the data or model quality or share results with the team. However, it is less convenient if you want to run your checks automatically and only react to meaningful issues.\n",
        "\n",
        "To integrate Evidently checks in the prediction pipeline, you can use the Test Suites functionality. They are also better suited to handle large datasets.\n",
        "\n",
        "Test Suites help compare the two datasets in a structured way. A Test Suite contains several individual tests. Each Test compares a specific value against a defined condition and returns an explicit pass/fail result. You can apply Tests to the whole dataset or individual columns.\n",
        "\n",
        "Just like with Reports, you can create a **custom Test Suite** or use one of the **Presets**.\n",
        "\n",
        "How does it work? \n",
        "Evidently automatically generates the test conditions based on the provided reference dataset. They are based on heuristics. For example, the test for column types fails if the column types do not match the reference. The test for the number of columns with missing values fails if the number is higher than in reference. The test for the share of drifting features fails if over 50% are drifting. You can easily pass custom conditions to set your own expectations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb973e5",
      "metadata": {},
      "source": [
        "##### TODO: Create a custom TestSuite\n",
        "- Test for missing values in columns\n",
        "- Test for rows with missing values\n",
        "- Test for constant columns\n",
        "- Test for duplicate rows\n",
        "- Test for duplicate columns\n",
        "- Test column types\n",
        "- Test for drifted columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2311155",
      "metadata": {
        "id": "f2311155"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d9528302",
      "metadata": {},
      "source": [
        "##### TODO: Display the performed tests\n",
        "- as dict\n",
        "- as JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20da511b",
      "metadata": {
        "id": "20da511b",
        "scrolled": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1c476f",
      "metadata": {
        "id": "3c1c476f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
